{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5892ed9-a476-44a6-b053-07d2955e1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model_pytorch import MySSD\n",
    "import torchvision\n",
    "from utils import *\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226fcf88-4a3a-410e-88ad-8d7046a71150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7368b55a-2180-4811-8e85-e22e1abe8b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f658296-b429-4fa4-b369-9870f36ff83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tiny(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Tiny, self).__init__()\n",
    "        \n",
    "        self.conv1=torch.nn.Conv2d(3,16,3)\n",
    "        self.conv2=torch.nn.Conv2d(3,8,3)\n",
    "        self.device =\"cpu\"\n",
    "    def forward(self, X):\n",
    "        anchor = multibox_prior(X, torch.tensor([0.1, 0.5], device=self.device), torch.tensor([0.1, 0.2], device=self.device))\n",
    "        X1 = self.conv1(X)\n",
    "        X2 = self.conv2(X)\n",
    "        \n",
    "        return anchor, X1, X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5730843c-8573-449b-8410-88fea7bdb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_model = torchvision.models.mobilenet_v2()\n",
    "torch_model = MySSD(num_classes=1, in_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67044326-dab6-4ab2-a84d-4bcc9b873183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2000, 0.2720]),\n",
       " tensor([0.3700, 0.4470]),\n",
       " tensor([0.5400, 0.6190]),\n",
       " tensor([0.7100, 0.7900]),\n",
       " tensor([0.8800, 0.9610])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.tensor([0.2, 0.272]), \n",
    "                        torch.tensor([0.37, 0.447]), \n",
    "                        torch.tensor([0.54, 0.619]),\n",
    "                      torch.tensor([0.71, 0.79]), \n",
    "                        torch.tensor([0.88, 0.961])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0eabdd-ac2c-4c17-bbdc-3048b58747cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.0000, 2.0000, 0.5000]),\n",
       " tensor([1.0000, 2.0000, 0.5000]),\n",
       " tensor([1.0000, 2.0000, 0.5000]),\n",
       " tensor([1.0000, 2.0000, 0.5000]),\n",
       " tensor([1.0000, 2.0000, 0.5000])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.tensor([1, 2, 0.5])] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4807fd63-b476-43a9-a1e5-c44376f020da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "keras_model =tf.keras.models.load_model(\"kerasModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ab81e9-7871-495b-9fdb-f1a10afa9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.rand((1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c44a70f-4daf-4ed8-b889-3e5363932a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.onnx.export(\n",
    "        torch_model,                  # PyTorch Model\n",
    "        sample_input,                    # Input tensor\n",
    "        \"model_onnx.onnx\",        # Output file (eg. 'output_model.onnx')\n",
    "        opset_version=12,       # Operator support version\n",
    "        input_names=['input'],   # Input tensor name (arbitary)\n",
    "        output_names=['output2', 'output3'] # Output tensor name (arbitary)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c441095-5f5d-44a1-aa6d-def41155c9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %input[FLOAT, 1x3x256x256]\\n) initializers (\\n  %auxiliaryconvs.conv8_1.weight[FLOAT, 128x128x1x1]\\n  %auxiliaryconvs.conv8_1.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv8_2.weight[FLOAT, 128x128x1x1]\\n  %auxiliaryconvs.conv8_2.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv9_1.weight[FLOAT, 128x128x1x1]\\n  %auxiliaryconvs.conv9_1.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv9_2.weight[FLOAT, 128x128x3x3]\\n  %auxiliaryconvs.conv9_2.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv10_1.weight[FLOAT, 128x128x1x1]\\n  %auxiliaryconvs.conv10_1.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv10_2.weight[FLOAT, 128x128x3x3]\\n  %auxiliaryconvs.conv10_2.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv11_1.weight[FLOAT, 128x128x1x1]\\n  %auxiliaryconvs.conv11_1.bias[FLOAT, 128]\\n  %auxiliaryconvs.conv11_2.weight[FLOAT, 128x128x3x3]\\n  %auxiliaryconvs.conv11_2.bias[FLOAT, 128]\\n  %enc1.conv1.weight[FLOAT, 16x3x3x3]\\n  %enc1.conv1.bias[FLOAT, 16]\\n  %enc1.conv2.weight[FLOAT, 16x16x3x3]\\n  %enc1.conv2.bias[FLOAT, 16]\\n  %enc2.conv1.weight[FLOAT, 32x16x3x3]\\n  %enc2.conv1.bias[FLOAT, 32]\\n  %enc2.conv2.weight[FLOAT, 32x32x3x3]\\n  %enc2.conv2.bias[FLOAT, 32]\\n  %enc3.conv1.weight[FLOAT, 64x32x3x3]\\n  %enc3.conv1.bias[FLOAT, 64]\\n  %enc3.conv2.weight[FLOAT, 64x64x3x3]\\n  %enc3.conv2.bias[FLOAT, 64]\\n  %enc4.conv1.weight[FLOAT, 128x64x3x3]\\n  %enc4.conv1.bias[FLOAT, 128]\\n  %enc4.conv2.weight[FLOAT, 128x128x3x3]\\n  %enc4.conv2.bias[FLOAT, 128]\\n  %cls_0.weight[FLOAT, 8x128x3x3]\\n  %cls_0.bias[FLOAT, 8]\\n  %bbox_0.weight[FLOAT, 16x128x3x3]\\n  %bbox_0.bias[FLOAT, 16]\\n  %cls_1.weight[FLOAT, 8x128x3x3]\\n  %cls_1.bias[FLOAT, 8]\\n  %bbox_1.weight[FLOAT, 16x128x3x3]\\n  %bbox_1.bias[FLOAT, 16]\\n  %cls_2.weight[FLOAT, 8x128x3x3]\\n  %cls_2.bias[FLOAT, 8]\\n  %bbox_2.weight[FLOAT, 16x128x3x3]\\n  %bbox_2.bias[FLOAT, 16]\\n  %cls_3.weight[FLOAT, 8x128x3x3]\\n  %cls_3.bias[FLOAT, 8]\\n  %bbox_3.weight[FLOAT, 16x128x3x3]\\n  %bbox_3.bias[FLOAT, 16]\\n  %120[INT64, 1]\\n  %121[INT64, 1]\\n) {\\n  %49 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input, %enc1.conv1.weight, %enc1.conv1.bias)\\n  %50 = Relu(%49)\\n  %51 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%50, %enc1.conv2.weight, %enc1.conv2.bias)\\n  %52 = Relu(%51)\\n  %53 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%52)\\n  %54 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%53, %enc2.conv1.weight, %enc2.conv1.bias)\\n  %55 = Relu(%54)\\n  %56 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%55, %enc2.conv2.weight, %enc2.conv2.bias)\\n  %57 = Relu(%56)\\n  %58 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%57)\\n  %59 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%58, %enc3.conv1.weight, %enc3.conv1.bias)\\n  %60 = Relu(%59)\\n  %61 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%60, %enc3.conv2.weight, %enc3.conv2.bias)\\n  %62 = Relu(%61)\\n  %63 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%62)\\n  %64 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%63, %enc4.conv1.weight, %enc4.conv1.bias)\\n  %65 = Relu(%64)\\n  %66 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%65, %enc4.conv2.weight, %enc4.conv2.bias)\\n  %67 = Relu(%66)\\n  %68 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%67, %auxiliaryconvs.conv8_1.weight, %auxiliaryconvs.conv8_1.bias)\\n  %69 = Relu(%68)\\n  %70 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [1, 1, 1, 1], strides = [2, 2]](%69, %auxiliaryconvs.conv8_2.weight, %auxiliaryconvs.conv8_2.bias)\\n  %71 = Relu(%70)\\n  %72 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%71, %auxiliaryconvs.conv9_1.weight, %auxiliaryconvs.conv9_1.bias)\\n  %73 = Relu(%72)\\n  %74 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%73, %auxiliaryconvs.conv9_2.weight, %auxiliaryconvs.conv9_2.bias)\\n  %75 = Relu(%74)\\n  %76 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%75, %auxiliaryconvs.conv10_1.weight, %auxiliaryconvs.conv10_1.bias)\\n  %77 = Relu(%76)\\n  %78 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [2, 2]](%77, %auxiliaryconvs.conv10_2.weight, %auxiliaryconvs.conv10_2.bias)\\n  %79 = Relu(%78)\\n  %80 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%79, %auxiliaryconvs.conv11_1.weight, %auxiliaryconvs.conv11_1.bias)\\n  %81 = Relu(%80)\\n  %82 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [0, 0, 0, 0], strides = [1, 1]](%81, %auxiliaryconvs.conv11_2.weight, %auxiliaryconvs.conv11_2.bias)\\n  %83 = Relu(%82)\\n  %84 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%71, %cls_0.weight, %cls_0.bias)\\n  %85 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%71, %bbox_0.weight, %bbox_0.bias)\\n  %86 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%75, %cls_1.weight, %cls_1.bias)\\n  %87 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%75, %bbox_1.weight, %bbox_1.bias)\\n  %88 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%79, %cls_2.weight, %cls_2.bias)\\n  %89 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%79, %bbox_2.weight, %bbox_2.bias)\\n  %90 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%83, %cls_3.weight, %cls_3.bias)\\n  %91 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%83, %bbox_3.weight, %bbox_3.bias)\\n  %92 = Transpose[perm = [0, 2, 3, 1]](%84)\\n  %93 = Flatten[axis = 1](%92)\\n  %94 = Transpose[perm = [0, 2, 3, 1]](%86)\\n  %95 = Flatten[axis = 1](%94)\\n  %96 = Transpose[perm = [0, 2, 3, 1]](%88)\\n  %97 = Flatten[axis = 1](%96)\\n  %98 = Transpose[perm = [0, 2, 3, 1]](%90)\\n  %99 = Flatten[axis = 1](%98)\\n  %100 = Concat[axis = 1](%93, %95, %97, %99)\\n  %101 = Shape(%100)\\n  %102 = Constant[value = <Scalar Tensor []>]()\\n  %103 = Gather[axis = 0](%101, %102)\\n  %106 = Unsqueeze[axes = [0]](%103)\\n  %109 = Concat[axis = 0](%106, %120, %121)\\n  %output2 = Reshape(%100, %109)\\n  %111 = Transpose[perm = [0, 2, 3, 1]](%85)\\n  %112 = Flatten[axis = 1](%111)\\n  %113 = Transpose[perm = [0, 2, 3, 1]](%87)\\n  %114 = Flatten[axis = 1](%113)\\n  %115 = Transpose[perm = [0, 2, 3, 1]](%89)\\n  %116 = Flatten[axis = 1](%115)\\n  %117 = Transpose[perm = [0, 2, 3, 1]](%91)\\n  %118 = Flatten[axis = 1](%117)\\n  %output3 = Concat[axis = 1](%112, %114, %116, %118)\\n  return %output2, %output3\\n}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model_onnx.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a Human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c4bb8f-f1aa-4c38-bdbc-51ba2252a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "\n",
    "tf_rep = prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c9313d-502a-4716-8bda-f6bcae009d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_path\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_path\\assets\n"
     ]
    }
   ],
   "source": [
    "tf_rep.export_graph(\"tf_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "056054ce-c1ef-4f99-96d5-46de26b5b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.saved_model.load(\"tf_path\")\n",
    "model.trainable = False\n",
    "\n",
    "input_tensor = tf.random.uniform([1, 3, 256, 256])\n",
    "out = model(**{'input': input_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ea7620-14b2-4405-b6bd-2d985dfe210c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25304/3470139634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "028a60f6-e646-41b4-b477-87bfbb7328f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output2': <tf.Tensor: shape=(1, 1452, 2), dtype=float32, numpy=\n",
       " array([[[ 0.0088798 , -0.01340563],\n",
       "         [-0.01260413, -0.00387777],\n",
       "         [-0.01406703, -0.03152488],\n",
       "         ...,\n",
       "         [ 0.00957541, -0.01929616],\n",
       "         [ 0.01558549, -0.02211975],\n",
       "         [-0.02065405,  0.02401579]]], dtype=float32)>,\n",
       " 'output3': <tf.Tensor: shape=(1, 5808), dtype=float32, numpy=\n",
       " array([[-0.00817955, -0.00544325,  0.03240756, ..., -0.01487938,\n",
       "          0.01330754,  0.01362312]], dtype=float32)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d6b5081-a933-4b5c-94e4-f13fc26d43fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "<unknown>:0: error: loc(callsite(callsite(\"Pad_10@__inference___call___744\" at \"StatefulPartitionedCall@__inference_signature_wrapper_853\") at \"StatefulPartitionedCall\")): operand #0 does not dominate this use\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"Pad_10@__inference___call___744\" at \"StatefulPartitionedCall@__inference_signature_wrapper_853\") at \"StatefulPartitionedCall\")): operand defined here\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\duong\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    212\u001b[0m                                                  \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                                                  enable_mlir_converter)\n\u001b[0m\u001b[0;32m    214\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\duong\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py\u001b[0m in \u001b[0;36mwrapped_toco_convert\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m     37\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m       enable_mlir_converter)\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: <unknown>:0: error: loc(callsite(callsite(\"Pad_10@__inference___call___744\" at \"StatefulPartitionedCall@__inference_signature_wrapper_853\") at \"StatefulPartitionedCall\")): operand #0 does not dominate this use\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"Pad_10@__inference___call___744\" at \"StatefulPartitionedCall@__inference_signature_wrapper_853\") at \"StatefulPartitionedCall\")): operand defined here\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25304/4011830055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconverter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf_path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Save the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\duong\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[0mconverter_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverter_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconverter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m     \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantizer_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\duong\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mconvert_saved_model\u001b[1;34m(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)\u001b[0m\n\u001b[0;32m    635\u001b[0m       \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# input_data, unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# debug_info_str, unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       enable_mlir_converter=True)\n\u001b[0m\u001b[0;32m    638\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\duong\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    214\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_executable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_toco_from_proto_bin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: <unknown>:0: error: loc(callsite(callsite(\"Pad_10@__inference___call___744\" at \"StatefulPartitionedCall@__inference_signature_wrapper_853\") at \"StatefulPartitionedCall\")): operand #0 does not dominate this use\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\n<unknown>:0: note: loc(callsite(callsite(\"Pad_10@__inference___call___744\" at \"StatefulPartitionedCall@__inference_signature_wrapper_853\") at \"StatefulPartitionedCall\")): operand defined here\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_path\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open(\"tflite_file.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30e400-985b-4999-a8a9-33d8866c13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290167f-032a-4ff8-ba6a-6278de245ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"tflite_file.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# get_tensor() returns a copy of the tensor data\n",
    "# use tensor() in order to get a pointer to the tensor\n",
    "output_data = interpreter.get_tensor(output_details[1]['index'])\n",
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2065e-6387-4693-a033-aa14953eb484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6f700-963d-468b-a307-6212506d603a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf04e35-e230-4da6-a6e8-ffbc76e08ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
